{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from gensim.models import Word2Vec\n",
    "# from itertools import *\n",
    "# dimen = 128\n",
    "# window = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string;\n",
    "import re;\n",
    "import random\n",
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import os\n",
    "from collections import defaultdict, Counter\n",
    "from tqdm import tqdm\n",
    "from torch_geometric.data import HeteroData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mm\u001b[0m={\n",
      "    num_nodes=4666,\n",
      "    y=[4666]\n",
      "  },\n",
      "  \u001b[1ma\u001b[0m={ num_nodes=5845 },\n",
      "  \u001b[1md\u001b[0m={ num_nodes=2271 },\n",
      "  \u001b[1mm_text_embed\u001b[0m={ x=[4666, 128] },\n",
      "  \u001b[1mm_net_embed\u001b[0m={ x=[4666, 128] },\n",
      "  \u001b[1mm_a_net_embed\u001b[0m={ x=[4666, 128] },\n",
      "  \u001b[1mm_d_net_embed\u001b[0m={ x=[4666, 128] },\n",
      "  \u001b[1ma_net_embed\u001b[0m={ x=[5845, 128] },\n",
      "  \u001b[1ma_text_embed\u001b[0m={ x=[5845, 128] },\n",
      "  \u001b[1md_net_embed\u001b[0m={ x=[2271, 128] },\n",
      "  \u001b[1md_text_embed\u001b[0m={ x=[2271, 128] },\n",
      "  \u001b[1m(m, walk, m)\u001b[0m={ edge_index=[2, 32862] },\n",
      "  \u001b[1m(m, walk, a)\u001b[0m={ edge_index=[2, 29894] },\n",
      "  \u001b[1m(m, walk, d)\u001b[0m={ edge_index=[2, 13656] },\n",
      "  \u001b[1m(a, walk, m)\u001b[0m={ edge_index=[2, 26087] },\n",
      "  \u001b[1m(a, walk, a)\u001b[0m={ edge_index=[2, 35045] },\n",
      "  \u001b[1m(a, walk, d)\u001b[0m={ edge_index=[2, 15898] },\n",
      "  \u001b[1m(d, walk, m)\u001b[0m={ edge_index=[2, 11136] },\n",
      "  \u001b[1m(d, walk, a)\u001b[0m={ edge_index=[2, 14009] },\n",
      "  \u001b[1m(d, walk, d)\u001b[0m={ edge_index=[2, 6256] }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "data = torch.load(\"data/data.pt\")\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_path = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_a_dict = defaultdict(list)\n",
    "\n",
    "# with open(data_path + \"m_a_list.txt\", 'r') as file:            \n",
    "#     lines = file.readlines()\n",
    "\n",
    "#     for i, line in enumerate(lines):\n",
    "#         enteries = re.split(',', line)\n",
    "#         m_node, a_node = enteries[0].strip(), enteries[1].strip()\n",
    "        \n",
    "#         m_a_dict[f'm{m_node}'].append(f'a{a_node}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m_d_dict = defaultdict(list)\n",
    "\n",
    "# with open(data_path + \"m_d_list.txt\", 'r') as file:            \n",
    "#     lines = file.readlines()\n",
    "\n",
    "#     for i, line in enumerate(lines):\n",
    "#         enteries = re.split(',', line)\n",
    "#         m_node, d_node = enteries[0].strip(), enteries[1].strip()\n",
    "        \n",
    "#         m_d_dict[f'm{m_node}'].append(f'd{d_node}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['a291', 'a1783', 'a1597']\n",
      "['d1763']\n"
     ]
    }
   ],
   "source": [
    "# print(m_a_dict[\"m456\"])\n",
    "# print(m_d_dict[\"m4\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_path + \"metapath_list.txt\", 'w') as file:  \n",
    "\n",
    "#     for m_node in list(m_d_dict.keys()):\n",
    "#         d_node = m_d_dict[m_node][0]\n",
    "#         for a_node in m_a_dict[m_node]:\n",
    "#             file.write(f'{m_node} {d_node} {a_node}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# with open(data_path + \"metapath_list2.txt\", 'w') as file:  \n",
    "\n",
    "#     for m_node in list(m_d_dict.keys()):\n",
    "#         d_node = m_d_dict[m_node][0]\n",
    "#         a_node = ' '.join(m_a_dict[m_node])\n",
    "#         file.write(f'{m_node} {d_node} {a_node}\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4666, 128])\n"
     ]
    }
   ],
   "source": [
    "with open(data_path + \"metapath_list.txt\", 'r') as file:            \n",
    "    lines = file.readlines()\n",
    "\n",
    "mp_num = 0\n",
    "m_embed = (data['m_text_embed'].x + data['m_net_embed'].x) / 2\n",
    "a_embed = (data['a_text_embed'].x + data['a_net_embed'].x) / 2\n",
    "d_embed = (data['d_text_embed'].x + data['d_net_embed'].x) / 2\n",
    "\n",
    "main_node = 0\n",
    "embed = None\n",
    "embedding = None\n",
    "print(m_embed.shape)\n",
    "\n",
    "with open(data_path + \"mp1_embed.txt\", 'w') as file1: \n",
    "    \n",
    "    with open(data_path + \"mp2_embed.txt\", 'w') as file2: \n",
    "        \n",
    "        with open(data_path + \"mp3_embed.txt\", 'w') as file3: \n",
    "            \n",
    "            for i, line in enumerate(lines):\n",
    "                \n",
    "                enteries = re.split(' ', line.strip())\n",
    "                m_node, d_node, a_node = int(enteries[0].strip()[1:]), int(enteries[1].strip()[1:]), int(enteries[2].strip()[1:])\n",
    "                \n",
    "                if main_node == m_node and i > 0: mp_num += 1\n",
    "                elif main_node != m_node and mp_num < 2: \n",
    "                    if mp_num == 1:\n",
    "                        file3.write(f'\\n')\n",
    "                    else:\n",
    "                        file2.write(f'\\n')\n",
    "                        file3.write(f'\\n')\n",
    "                    mp_num = 0\n",
    "                else: mp_num = 0\n",
    "                \n",
    "                if mp_num == 0: output_file = file1\n",
    "                elif mp_num == 1: output_file = file2\n",
    "                else: output_file = file3\n",
    "                    \n",
    "                embed = torch.cat((m_embed[m_node, :], a_embed[a_node, :], d_embed[d_node, :]))\n",
    "                embedding = ' '.join(map(str, embed.tolist()))\n",
    "\n",
    "                output_file.write(f'{embedding}\\n')\n",
    "                main_node = m_node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mp_tensor = torch.empty(0)\n",
    "# mp_list = []\n",
    "# a=-1\n",
    "\n",
    "# with open(data_path + \"metapath_list2.txt\", 'r') as file:\n",
    "#     lines = file.readlines()\n",
    "\n",
    "#     for i, line in enumerate(lines):\n",
    "#         entries = re.split(' ', line.strip())\n",
    "#         node_list = [int(entry[1:]) for entry in entries]\n",
    "#         if len(node_list) == 4: \n",
    "#             node_list.append(a)\n",
    "#             a-= 1\n",
    "#         if len(node_list) == 3: \n",
    "#             node_list.append(a)\n",
    "#             a-=1\n",
    "#             node_list.append(a)\n",
    "#             a-=1\n",
    "#         # print(node_list)\n",
    "#         mp_list.append(torch.tensor([node_list]))\n",
    "        \n",
    "#     mp_tensor =  torch.cat(mp_list, dim = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[   0,  577, 3760, 4074,   87],\n",
      "        [   1, 1272, 5352, 1331, 2324],\n",
      "        [   2, 1074, 1509, 1988, 2916],\n",
      "        ...,\n",
      "        [4663,  216, 4970, 4927, 3447],\n",
      "        [4664, 1309, 5249, 1192,  161],\n",
      "        [4665,  775, 4236, 3194,  999]])\n"
     ]
    }
   ],
   "source": [
    "# print(mp_tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def find_matching_pairs(column_tensor):\n",
    "#     num_rows = column_tensor.size(0)\n",
    "#     matching_pairs = []\n",
    "\n",
    "#     for i in tqdm(range(num_rows), desc=\"Processing rows\"):\n",
    "#         for j in range(i + 1, num_rows):\n",
    "\n",
    "#             source = [column_tensor[i].item()] if column_tensor[i].numel() == 1 else column_tensor[i,:].tolist()\n",
    "#             target = [column_tensor[j].item()] if column_tensor[j].numel() == 1 else column_tensor[j,:].tolist()\n",
    "#             for k in source: \n",
    "#                 if k in target:\n",
    "#                     if (i,j) == (1,12): print(\"poop\")\n",
    "#                     matching_pairs.append((i, j))\n",
    "\n",
    "#     return matching_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 577, 1272, 1074,  ...,  216, 1309,  775])\n"
     ]
    }
   ],
   "source": [
    "# print(mp_tensor[:,1])\n",
    "# from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   0%|          | 8/4666 [00:00<02:16, 34.14it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 4666/4666 [01:33<00:00, 50.09it/s] \n"
     ]
    }
   ],
   "source": [
    "# pairs1 = find_matching_pairs(mp_tensor[:,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows:   0%|          | 6/4666 [00:00<03:08, 24.79it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "poop\n",
      "poop\n",
      "poop\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing rows: 100%|██████████| 4666/4666 [02:03<00:00, 37.91it/s] \n"
     ]
    }
   ],
   "source": [
    "# pairs2 = find_matching_pairs(mp_tensor[:,2:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7509 43987 51496\n"
     ]
    }
   ],
   "source": [
    "# pairs = pairs1+pairs2\n",
    "# print(len(pairs1), len(pairs2), len(pairs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from collections import Counter\n",
    "\n",
    "# def write_unique_tuples_to_file(pairs, file_path):\n",
    "#     # Count the occurrences of each tuple\n",
    "#     tuple_counts = Counter(pairs)\n",
    "\n",
    "#     with open(file_path, 'w') as file:\n",
    "#         for pair, count in tuple_counts.items():\n",
    "#             # Write the tuple along with its count\n",
    "#             file.write(f\"{pair[0]} {pair[1]} {count}\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write_unique_tuples_to_file(pairs, \"data/edges_list.txt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "M_n = 4666\n",
    "embed_d = 128*3\n",
    "data_path = \"data/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "mp1_embed = torch.zeros(M_n, embed_d, dtype=torch.float32)\n",
    "mp2_embed = torch.zeros(M_n, embed_d, dtype=torch.float32)\n",
    "mp3_embed = torch.zeros(M_n, embed_d, dtype=torch.float32)\n",
    "\n",
    "f_names = [\"mp1_embed.txt\", \"mp2_embed.txt\", \"mp3_embed.txt\"]\n",
    "\n",
    "for f_name in f_names:\n",
    "    with open(data_path + f_name, 'r') as file:            \n",
    "        lines = file.readlines()      \n",
    "\t\t\t\n",
    "        for i, line in enumerate(lines):\n",
    "            entries = line.strip().split()\n",
    "            if entries == []: continue\n",
    "            if f_name == 'mp1_embed.txt':\n",
    "                mp1_embed[i] = torch.tensor([float(x) for x in entries]) \n",
    "            elif f_name == 'mp2_embed.txt':\n",
    "                mp2_embed[i] = torch.tensor([float(x) for x in entries]) \n",
    "            else:\n",
    "                mp3_embed[i] = torch.tensor([float(x) for x in entries]) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "m_class = torch.full((M_n,), -1, dtype=torch.long)\n",
    "with open(data_path + \"m_class.txt\", 'r') as file:            \n",
    "    lines = file.readlines()\n",
    "    for i, line in enumerate(lines):\n",
    "        entries =  line.strip().split(',')\n",
    "        m_class[int(entries[0])] = int(entries[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([4666]) torch.Size([4666, 384]) torch.Size([4666, 384])\n"
     ]
    }
   ],
   "source": [
    "print(m_class.shape, mp1_embed.shape, mp2_embed.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0, 25] 1.0\n",
      "[0, 279] 1.0\n",
      "[0, 282] 1.0\n",
      "[0, 585] 1.0\n",
      "[0, 2392] 1.0\n"
     ]
    }
   ],
   "source": [
    "m_a_edge_index = torch.empty(0)\n",
    "m_a_edge_weight = torch.zeros((50253,), dtype=torch.float32)\n",
    "m_a_list = []\n",
    "\n",
    "with open(data_path + \"edges_list.txt\", 'r') as file:\n",
    "    lines = file.readlines()\n",
    "    \n",
    "    for i, line in enumerate(lines):\n",
    "        entries =  line.strip().split()\n",
    "        edge_list = [int(x) for x in entries[0:2]]\n",
    "        weight = float(entries[2])\n",
    "        if i < 5: print(edge_list, weight)\n",
    "        m_a_list.append(torch.tensor([edge_list]))\n",
    "        m_a_edge_weight[i] = weight\n",
    "\n",
    "    # Concatenate the list of tensors into a single tensor\n",
    "    m_a_edge_index = torch.cat(m_a_list, dim=0).t().contiguous()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 50253]) torch.Size([50253])\n"
     ]
    }
   ],
   "source": [
    "print(m_a_edge_index.shape, m_a_edge_weight.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = HeteroData()\n",
    "    \n",
    "data['m'].num_nodes = 4666\n",
    "\n",
    "data['mp1'].x = mp1_embed\n",
    "data['mp2'].x = mp2_embed\n",
    "data['mp3'].x = mp3_embed\n",
    "    \n",
    "data['mp'].edge_index = m_a_edge_index\n",
    "data['mp'].edge_weight = m_a_edge_weight \n",
    "data['mp'].y = m_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HeteroData(\n",
      "  \u001b[1mm\u001b[0m={ num_nodes=4666 },\n",
      "  \u001b[1mmp1\u001b[0m={ x=[4666, 384] },\n",
      "  \u001b[1mmp2\u001b[0m={ x=[4666, 384] },\n",
      "  \u001b[1mmp3\u001b[0m={ x=[4666, 384] },\n",
      "  \u001b[1mmp\u001b[0m={\n",
      "    edge_index=[2, 50253],\n",
      "    edge_weight=[50253],\n",
      "    y=[4666]\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(data, 'data.pt')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
