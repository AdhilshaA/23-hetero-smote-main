{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing libraries and directory settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "from collections import Counter \n",
    "import json\n",
    "from tqdm import tqdm\n",
    "from gensim.models import Word2Vec, KeyedVectors\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "data_dir = '/home/deependra/project/23-hetero-smote/HeteroG/data/yelp_kaggle/'\n",
    "\n",
    "business_file = 'yelp_academic_dataset_business.json'\n",
    "review_file = 'yelp_academic_dataset_review.json'\n",
    "user_file = 'yelp_academic_dataset_user.json'\n",
    "checkin_file = 'yelp_academic_dataset_checkin.json'\n",
    "tip_file = 'yelp_academic_dataset_tip.json'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Preparing the subset of yelp dataset for the analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading json files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150346/150346 [00:01<00:00, 76281.43it/s] "
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of business data:  150346\n",
      "business data columns:  14\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load business data\n",
    "\n",
    "business_data = []\n",
    "with open(data_dir + business_file, encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in tqdm(lines):\n",
    "        business_data.append(list(json.loads(line).values()))\n",
    "    business_header = dict(zip(json.loads(line).keys(), range(len(json.loads(line).keys()))))\n",
    "        \n",
    "print('Total number of business data: ', len(business_data))\n",
    "print('business data columns: ', len(business_header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990280/6990280 [00:43<00:00, 159271.51it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of review data:  6990280\n",
      "review data columns:  9\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "review_data = []\n",
    "with open(data_dir + review_file, encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in tqdm(lines):\n",
    "        review_data.append(list(json.loads(line).values()))\n",
    "    review_header = dict(zip(json.loads(line).keys(), range(len(json.loads(line).keys()))))\n",
    "\n",
    "print('Total number of review data: ', len(review_data))\n",
    "print('review data columns: ', len(review_header))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987897/1987897 [00:17<00:00, 114433.81it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of user data:  1987897\n",
      "user data columns:  22\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Load user data\n",
    "user_data = []\n",
    "with open(data_dir + user_file, encoding='utf-8') as f:\n",
    "    lines = f.readlines()\n",
    "    for line in tqdm(lines):\n",
    "        user_data.append(list(json.loads(line).values()))\n",
    "    user_header = dict(zip(json.loads(line).keys(), range(len(json.loads(line).keys()))))\n",
    "    \n",
    "print('Total number of user data: ', len(user_data))\n",
    "print('user data columns: ', len(user_header))\n",
    "\n",
    "del lines, line"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "business header: \n",
      "{'business_id': 0, 'name': 1, 'address': 2, 'city': 3, 'state': 4, 'postal_code': 5, 'latitude': 6, 'longitude': 7, 'stars': 8, 'review_count': 9, 'is_open': 10, 'attributes': 11, 'categories': 12, 'hours': 13}\n",
      "\n",
      "user header: \n",
      "{'user_id': 0, 'name': 1, 'review_count': 2, 'yelping_since': 3, 'useful': 4, 'funny': 5, 'cool': 6, 'elite': 7, 'friends': 8, 'fans': 9, 'average_stars': 10, 'compliment_hot': 11, 'compliment_more': 12, 'compliment_profile': 13, 'compliment_cute': 14, 'compliment_list': 15, 'compliment_note': 16, 'compliment_plain': 17, 'compliment_cool': 18, 'compliment_funny': 19, 'compliment_writer': 20, 'compliment_photos': 21}\n",
      "\n",
      "review header: \n",
      "{'review_id': 0, 'user_id': 1, 'business_id': 2, 'stars': 3, 'useful': 4, 'funny': 5, 'cool': 6, 'text': 7, 'date': 8}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(f'business header: \\n{business_header}\\n')\n",
    "print(f'user header: \\n{user_header}\\n')\n",
    "print(f'review header: \\n{review_header}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Checking and adding businesses, reviews, and users"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/150346 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 150346/150346 [00:00<00:00, 831919.74it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of businesses: 52268\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "category = 'Restaurants'\n",
    "\n",
    "business_ids = []\n",
    "for i in tqdm(range(len(business_data))):\n",
    "    if business_data[i][business_header['categories']] and category in business_data[i][business_header['categories']]:\n",
    "        business_ids.append(business_data[i][business_header[\"business_id\"]])\n",
    "\n",
    "business_ids = dict(zip(business_ids, range(len(business_ids))))\n",
    "print(f'Number of businesses: {len(business_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting all review ids and user ids...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990280/6990280 [00:10<00:00, 662465.43it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of reviews: 3189734\n",
      "stars: 1stars: 567185, 3stars: 543108, 5stars: 2079441\n",
      "Current Number of users: 1243712\n",
      "previous number of businesses: 52268\n",
      "Current number of businesses: 52244\n"
     ]
    }
   ],
   "source": [
    "review_ids = []\n",
    "user_ids = []\n",
    "business_ids2 = []\n",
    "stars = [0,0,0] # stars 1, 3, 5\n",
    "print('Collecting all review ids and user ids...')\n",
    "for i in tqdm(range(len(review_data))):\n",
    "    if review_data[i][review_header['business_id']] in business_ids.keys() and review_data[i][review_header['text']] and review_data[i][review_header['stars']] in [1, 3, 5]:\n",
    "        review_ids.append(review_data[i][review_header['review_id']])\n",
    "        user_ids.append(review_data[i][review_header['user_id']])\n",
    "        business_ids2.append(review_data[i][review_header['business_id']])\n",
    "        stars[int(review_data[i][review_header['stars']])//2] += 1\n",
    "\n",
    "# setting up review ids\n",
    "print(f'Number of reviews: {len(review_ids)}')\n",
    "print(f'stars: 1stars: {stars[0]}, 3stars: {stars[1]}, 5stars: {stars[2]}')\n",
    "\n",
    "# setting up user ids\n",
    "user_ids = list(set(user_ids))\n",
    "print(f'Current Number of users: {len(user_ids)}')\n",
    "\n",
    "print(f'previous number of businesses: {len(business_ids)}')\n",
    "business_ids = list(set(business_ids2))\n",
    "print(f'Current number of businesses: {len(business_ids)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting all user ids...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1987897/1987897 [00:01<00:00, 1913375.64it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking for unuseable user ids...\n",
      "Number of bad user ids: 5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990280/6990280 [00:03<00:00, 1991477.17it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of bad review ids (same as bad user ids): 5\n",
      "Final Number of users: 1243707\n",
      "Final Number of reviews: 3189729\n",
      "Final Number of businesses: 52244\n"
     ]
    }
   ],
   "source": [
    "# checking for unuseable user ids\n",
    "\n",
    "all_user_ids = []\n",
    "print('Collecting all user ids...')\n",
    "for i in tqdm(range(len(user_data))):\n",
    "    all_user_ids.append(user_data[i][user_header['user_id']])\n",
    "    \n",
    "print('Checking for unuseable user ids...')\n",
    "bad_user_ids = set(user_ids) - set(all_user_ids)\n",
    "print(f'Number of bad user ids: {len(bad_user_ids)}')\n",
    " \n",
    "bad_review_ids = [] # from bad user ids\n",
    "\n",
    "for i in tqdm(range(len(review_data))):\n",
    "    if review_data[i][review_header['user_id']] in bad_user_ids and review_data[i][review_header['review_id']] in review_ids:\n",
    "        bad_review_ids.append(review_data[i][review_header['review_id']])\n",
    "        \n",
    "print(f'Number of bad review ids (same as bad user ids): {len(bad_review_ids)}')\n",
    "\n",
    "# removing bad user ids\n",
    "user_ids = list(set(user_ids) - bad_user_ids)\n",
    "\n",
    "# removing bad review ids\n",
    "review_ids = list(set(review_ids) - set(bad_review_ids))\n",
    "\n",
    "user_ids = dict(zip(user_ids, range(len(user_ids))))\n",
    "review_ids = dict(zip(review_ids, range(len(review_ids))))\n",
    "business_ids = dict(zip(business_ids, range(len(business_ids))))\n",
    "\n",
    "print(f'Final Number of users: {len(user_ids)}')\n",
    "print(f'Final Number of reviews: {len(review_ids)}')\n",
    "print(f'Final Number of businesses: {len(business_ids)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mapping the business_id to review_id and them to user_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 6990280/6990280 [00:29<00:00, 235014.04it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of user-review edges: 3189729\n",
      "Number of review-business edges: 3189729\n",
      "Number of review samples with classes: 3189729\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "ur_edges = []\n",
    "rb_edges = []\n",
    "r_class = [] # 0: 1 stars, 1: 3 stars, 2: 5 stars\n",
    "\n",
    "user_id_index = review_header['user_id']\n",
    "business_id_index = review_header['business_id']\n",
    "review_id_index = review_header['review_id']\n",
    "star_index = review_header['stars']\n",
    "\n",
    "for i in tqdm(range(len(review_data))):\n",
    "    if review_data[i][review_id_index] in review_ids:\n",
    "        ur_edges.append([user_ids[review_data[i][user_id_index]], review_ids[review_data[i][review_id_index]]])\n",
    "        rb_edges.append([review_ids[review_data[i][review_id_index]], business_ids[review_data[i][business_id_index]]])\n",
    "        r_class.append([review_ids[review_data[i][review_id_index]],int(review_data[i][star_index])//2])\n",
    "        \n",
    "print(f'Number of user-review edges: {len(ur_edges)}')\n",
    "print(f'Number of review-business edges: {len(rb_edges)}')\n",
    "print(f'Number of review samples with classes: {len(r_class)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save the business_id, review_id, and user_id to txt files\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saving business ids...\n",
      "Saving user ids...\n",
      "Saving review ids...\n",
      "Saving user review edges...\n",
      "Saving review business edges...\n",
      "Saving review classes...\n"
     ]
    }
   ],
   "source": [
    "print('Saving business ids...')\n",
    "with open(data_dir + 'business_ids.txt', 'w') as f:\n",
    "    for business,id in business_ids.items():\n",
    "        f.write(f'{id}\\t{business}\\n')\n",
    "print('Saving user ids...')\n",
    "with open(data_dir + 'user_ids.txt', 'w') as f:\n",
    "    for user,id in user_ids.items():\n",
    "        f.write(f'{id}\\t{user}\\n')\n",
    "print('Saving review ids...')\n",
    "with open(data_dir + 'review_ids.txt', 'w') as f:\n",
    "    for review,id in review_ids.items():\n",
    "        f.write(f'{id}\\t{review}\\n')\n",
    "print('Saving user review edges...')\n",
    "with open(data_dir + 'ur_edges.txt', 'w') as f:\n",
    "    for edge in ur_edges:\n",
    "        f.write(f'{edge[0]}\\t{edge[1]}\\n')\n",
    "print('Saving review business edges...')\n",
    "with open(data_dir + 'rb_edges.txt', 'w') as f:\n",
    "    for edge in rb_edges:\n",
    "        f.write(f'{edge[0]}\\t{edge[1]}\\n')\n",
    "print('Saving review classes...')\n",
    "with open(data_dir + 'r_class.txt', 'w') as f:\n",
    "    for edge in r_class:\n",
    "        f.write(f'{edge[0]}\\t{edge[1]}\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random walk with restart"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 52244/52244 [00:00<00:00, 844974.43it/s]\n",
      "100%|██████████| 1243707/1243707 [00:01<00:00, 801534.27it/s]\n",
      "100%|██████████| 3189729/3189729 [00:04<00:00, 749605.51it/s]\n",
      "100%|██████████| 3189729/3189729 [00:09<00:00, 334899.67it/s]\n",
      "100%|██████████| 3189729/3189729 [00:07<00:00, 404952.30it/s]\n",
      "100%|██████████| 3189729/3189729 [00:06<00:00, 461344.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TOtal number of business ids: 52244\n",
      "TOtal number of user ids: 1243707\n",
      "TOtal number of review ids: 3189729\n",
      "TOtal number of ur edges: 3189729\n",
      "TOtal number of rb edges: 3189729\n",
      "TOtal number of r samples with classes: 3189729\n"
     ]
    }
   ],
   "source": [
    "load_data = True\n",
    "if load_data:\n",
    "    business_ids = {}\n",
    "    user_ids = {}\n",
    "    review_ids = {}\n",
    "    ur_edges = []\n",
    "    rb_edges = []\n",
    "    r_class = []\n",
    "    \n",
    "    with open(data_dir + 'business_ids.txt', 'r') as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            business_ids[line.strip().split('\\t')[1]] = int(line.strip().split('\\t')[0])\n",
    "    \n",
    "    with open(data_dir + 'user_ids.txt', 'r') as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            user_ids[line.strip().split('\\t')[1]] = int(line.strip().split('\\t')[0])\n",
    "    \n",
    "    with open(data_dir + 'review_ids.txt', 'r') as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            review_ids[line.strip().split('\\t')[1]] = int(line.strip().split('\\t')[0])\n",
    "    \n",
    "    with open(data_dir + 'ur_edges.txt', 'r') as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            ur_edges.append([int(line.strip().split('\\t')[0]), int(line.strip().split('\\t')[1])])\n",
    "    \n",
    "    with open(data_dir + 'rb_edges.txt', 'r') as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            rb_edges.append([int(line.strip().split('\\t')[0]), int(line.strip().split('\\t')[1])])\n",
    "            \n",
    "    with open(data_dir + 'r_class.txt', 'r') as f:\n",
    "        for line in tqdm(f.readlines()):\n",
    "            r_class.append([int(line.strip().split('\\t')[0]), int(line.strip().split('\\t')[1])])\n",
    "            \n",
    "    print(f'TOtal number of business ids: {len(business_ids)}')\n",
    "    print(f'TOtal number of user ids: {len(user_ids)}')\n",
    "    print(f'TOtal number of review ids: {len(review_ids)}')\n",
    "    print(f'TOtal number of ur edges: {len(ur_edges)}')\n",
    "    print(f'TOtal number of rb edges: {len(rb_edges)}')\n",
    "    print(f'TOtal number of r samples with classes: {len(r_class)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Creating all neighbors dict for each node...\n",
      "nodes created:  4485680\n",
      "Finding all neighbors of each node...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3189729/3189729 [00:14<00:00, 224142.13it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of nodes:  4485680\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# finding all neighbors of each node\n",
    "\n",
    "print('Creating all neighbors dict for each node...')\n",
    "all_neighbors = {f'b{id}':[] for name,id in business_ids.items()}\n",
    "all_neighbors.update({f'u{id}':[] for name,id in user_ids.items()})\n",
    "all_neighbors.update({f'r{id}':[] for name,id in review_ids.items()})\n",
    "print('nodes created: ', len(all_neighbors))\n",
    "print('Finding all neighbors of each node...')\n",
    "for i in tqdm(range(len(ur_edges))):\n",
    "    all_neighbors[f'u{ur_edges[i][0]}'].append(f'r{ur_edges[i][1]}')\n",
    "    all_neighbors[f'r{ur_edges[i][1]}'].append(f'u{ur_edges[i][0]}')\n",
    "    \n",
    "    all_neighbors[f'r{rb_edges[i][0]}'].append(f'b{rb_edges[i][1]}')\n",
    "    all_neighbors[f'b{rb_edges[i][1]}'].append(f'r{rb_edges[i][0]}')\n",
    "    \n",
    "print('Total number of nodes: ', len(all_neighbors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4485680/4485680 [15:13<00:00, 4910.53it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of random walks: 4485680\n",
      "singular random walk, m0: ['r1151397', 'u0', 'r2262528', 'u0', 'r1151397', 'r2262528', 'u0', 'r1151397', 'r2262528', 'b18783', 'r2262528', 'b18783', 'r729220', 'b18783', 'r2168078', 'u573797', 'r1151397', 'u0', 'r1151397', 'u0', 'r2262528', 'b18783', 'r3168798', 'u886307', 'r1151397', 'b48712', 'r2262528', 'b18783', 'r2262528', 'b18783', 'r2262528', 'b18783', 'r1151397', 'r1151397', 'u0', 'r1151397', 'u0', 'r2262528', 'r2262528', 'r1151397', 'b48712', 'r2231977', 'r1151397', 'u0', 'r2262528', 'r1151397', 'u0', 'r1151397', 'b48712', 'r3029656', 'r1151397', 'u0', 'r2262528', 'r2262528', 'b18783', 'r1338241', 'r2262528', 'u0', 'r1151397', 'r1151397', 'u0', 'r2262528', 'u0', 'r2262528', 'u0', 'r1151397', 'u0', 'r2262528', 'b18783', 'u0', 'u0', 'b48712', 'b48712', 'b48712', 'u0', 'b48712', 'u0', 'u0', 'b18783', 'u473293', 'b18783', 'u0', 'u0', 'b48712', 'u0', 'u0', 'b48712', 'u0', 'u0', 'u0', 'u691489', 'u691489', 'u0', 'u0', 'u0', 'u0', 'u0', 'u0', 'u0', 'u0']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# step1: random walk with a restart (HAN paper method)\n",
    "\n",
    "length = 100\n",
    "prob_restart = 0.5\n",
    "max_samples = {'b' : 20, 'u': 40, 'r': 40} # should add up to length\n",
    "\n",
    "random_walks = {}\n",
    "for node in tqdm(list(all_neighbors.keys())):\n",
    "    random_walks[node] = []\n",
    "    curr_node = node\n",
    "    neighbors = 0\n",
    "    neigh_b = 0\n",
    "    neigh_u = 0\n",
    "    neigh_r = 0\n",
    "    while neighbors < length:\n",
    "        p = random.random()\n",
    "        if p < prob_restart:\n",
    "            curr_node = node\n",
    "        else:\n",
    "            curr_node = random.choice(all_neighbors[curr_node])\n",
    "            if curr_node[0] == 'b' and neigh_b < max_samples['b']:\n",
    "                random_walks[node].append(curr_node)\n",
    "                neigh_b += 1\n",
    "                neighbors += 1\n",
    "            elif curr_node[0] == 'u' and neigh_u < max_samples['u']:\n",
    "                random_walks[node].append(curr_node)\n",
    "                neigh_u += 1\n",
    "                neighbors += 1\n",
    "            elif curr_node[0] == 'r' and neigh_r < max_samples['r']:\n",
    "                random_walks[node].append(curr_node)\n",
    "                neigh_r += 1\n",
    "                neighbors += 1\n",
    "\n",
    "print(f\"number of random walks: {len(random_walks)}\")\n",
    "print(f\"singular random walk, {'m0'}: {random_walks['u0']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4485680/4485680 [00:20<00:00, 218124.06it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating random walks file\n",
    "with open(data_dir + 'random_walks.txt', 'w') as f:\n",
    "    for key, value in tqdm(random_walks.items()):\n",
    "        f.write(f\"{key}:{','.join(value)}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Grouping and finding top neighbors of each node type for all node"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4485680/4485680 [04:28<00:00, 16681.13it/s]\n"
     ]
    }
   ],
   "source": [
    "# step2: Grouping different types of neighbors based on frequency(HAN paper method)\n",
    "\n",
    "top_k = {'b' : 6, 'u' : 12, 'r': 12} # top k neighbors to be considered for each type of node\n",
    "                                     # preferred to be less than the sample size in random walk for the optional last step\n",
    "\n",
    "top_neighbors = {}\n",
    "for node in tqdm(list(all_neighbors.keys())):\n",
    "    \n",
    "    # initializing top_neighbors categores for that node\n",
    "    top_neighbors[node] = {'b' : [], 'u' : [], 'r': []}\n",
    "    \n",
    "    # finding neighbors of different types\n",
    "    neigh_b = []\n",
    "    neigh_u = []\n",
    "    neigh_r = []\n",
    "    for neigh in random_walks[node]:\n",
    "        if neigh[0] == 'b':\n",
    "            neigh_b.append(neigh)\n",
    "        elif neigh[0] == 'u':\n",
    "            neigh_u.append(neigh)\n",
    "        elif neigh[0] == 'r':\n",
    "            neigh_r.append(neigh)\n",
    "    \n",
    "    # finding top k neighbors (and their countes)\n",
    "    top_b = Counter(neigh_b).most_common(top_k['b'])\n",
    "    top_u = Counter(neigh_u).most_common(top_k['u'])\n",
    "    top_r = Counter(neigh_r).most_common(top_k['r'])\n",
    "    \n",
    "    # adding top k neighbors to top_neighbors in nodes respective category\n",
    "    top_neighbors[node]['b'].extend([i[0] for i in top_b])\n",
    "    top_neighbors[node]['u'].extend([i[0] for i in top_u])\n",
    "    top_neighbors[node]['r'].extend([i[0] for i in top_r])\n",
    "\n",
    "\n",
    "    # adding random neighbors if less than top k\n",
    "    if len(top_b) < top_k['b']:\n",
    "        top_neighbors[node]['b'].extend(random.sample(neigh_b,top_k['b'] - len(top_b)))\n",
    "    if len(top_u) < top_k['u']:\n",
    "        top_neighbors[node]['u'].extend(random.sample(neigh_u,top_k['u'] - len(top_u)))\n",
    "    if len(top_r) < top_k['r']:\n",
    "        top_neighbors[node]['r'].extend(random.sample(neigh_r,top_k['r'] - len(top_r)))\n",
    "\n",
    "del neigh_b, neigh_u, top_b, top_u"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 4485680/4485680 [00:12<00:00, 355653.37it/s]\n"
     ]
    }
   ],
   "source": [
    "# creating top neighbors file\n",
    "with open(data_dir + 'node_neighbors_top.txt', 'w') as f:\n",
    "    for key, value in tqdm(top_neighbors.items()):\n",
    "        f.write(f\"{key}:{','.join(value['b'])};{','.join(value['u'])};{','.join(value['r'])}\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## PyG HeteroData object creation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "n_nodes: 4485680\n"
     ]
    }
   ],
   "source": [
    "# TOtal number of business ids: 52244\n",
    "# TOtal number of user ids: 1243707\n",
    "# TOtal number of review ids: 3189729\n",
    "# TOtal number of ur edges: 3189729\n",
    "# TOtal number of rb edges: 3189729\n",
    "# TOtal number of r samples with classes: 3189729\n",
    "\n",
    "\n",
    "Nb = 52244 # business nodes\n",
    "Nu = 1243707 # user nodes\n",
    "Nr = 3189729 # review edges"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "rfmidc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
